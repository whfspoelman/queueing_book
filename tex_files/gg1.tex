\section
[$G/G/1$  and $G/G/c$ Queue: Approximations]
{$\mathbf{G/G/1}$  and $\mathbf{G/G/c}$ Queue: Approximations}
\label{sec:gg1}


\subsection*{Theory and Exercises}

\Opensolutionfile{hint}
\Opensolutionfile{ans}





In manufacturing settings it is quite often the case that the arrival
process at a station is not Poisson. For instance, if processing times
at a station are nearly constant, and the jobs of this station are
sent to a second station for further processing, the inter-arrival
times at the second station must be more or less equal. Hence, in this
case, the SCV of the arrivals at the second station $C_{a,2}^2$ is
most probably smaller than 1. As a consequence the
Pollaczek-Khinchine formula for the $M/G/1$-queue can no longer be
reliably used to compute the average waiting times.  As a second,
trivial case, if the inter-arrival times of jobs are 1 hour always and
service times 59 minutes always, there simply cannot be queue. Thus,
the $M/G/1$ waiting time formula cannot, and should not, be applied to
approximate the average waiting time of the $G/G/1$ queue. 

There is no formula as yet by which the average waiting times for the
$G/G/1$ queue can be computed; only approximations are available. One
such simple and robust approximation is based on the following
observation. Recall  the waiting time in queue for the $M/M/1$ queue:
\begin{equation*}
  \E{W_Q(M/M/1)} = \frac{\rho}{1-\rho} \E S = 
\frac{1_a + 1_b}2 \frac{\rho}{1-\rho} \E S,
\end{equation*}
where we label the number $1$ with $a$ and $b$. When generalizing this
result to the $M/G/1$ queue we get
\begin{equation*}
  \E{W_Q(M/G/1)} = \frac{1_a + C_s^2}2 \frac{\rho}{1-\rho} \E S.
\end{equation*}
Thus, $1_b$ in the expression for the $M/M/1$ queue is replaced by
$C_s^2$ in the expression for the $M/G/1$ queue. As a second
generalization, Kingman proposed to replace $1_a$ in this formula by
the SCV of the inter-arrival times
\begin{equation*}
C_a^2 = \frac{\V X}{(\E X)^2},
\end{equation*}
resulting in
\begin{equation*}
  \E{W_Q(G/G/1)} \approx \frac{C_a^2 + C_s^2}2 \frac{\rho}{1-\rho} \E S.
\end{equation*}

This formula is reasonably accurate; for related expressions we refer
to \citet{bolch06:_queuein_networ_markov_chain} and
\citet{hall91:_queuein_method_servic_manuf}. With Little's law we can
compute $\E{L_Q}$ from the above. Moreover, $\E W = \E{W_Q} + \E S$,
and so on, c.f., Section~\ref{sec:some-usef-ident}



It is crucial to memorize the \emph{scaling} relations that can be
seen from the $G/G/1$ waiting time formula. Roughly:
\begin{enumerate}
\item $\E{W_Q} \sim (1-\rho)^{-1}$. The consequence is that the waiting
  time increases \emph{very steeply} when~$\rho$ is large, hence is
  very sensitive to the actual value of $\rho$ when $\rho$ is large.
\item $\E{W_Q} \sim C_a^2$ and $\E{W_Q} \sim C_s^2$. Hence, reductions
  of the variation of the inter-arrival and service times do affect the
  waiting time, but only linearly.
\item $\E{W_Q} \sim \E S$. Thus, working in smaller job sizes reduces
  the waiting time as well  . The average queue length does not decrease by
  working with smaller batches, but jobs are more `uniformly spread'
  over the queue. This effect lies behind the idea of
  `lot-splitting', i.e., rather than process large jobs, split jobs
  into multiple small jobs (assuming that setup times are negligible),
  so that the waiting time per job can be reduced.
\end{enumerate}

These insights prove very useful when trying to reduce waiting times
in any practical situation. First try to reduce the load (by blocking
demand or increasing the capacity), then try to reduce the variability
(e.g., by planning the arrival times of jobs), and finally, attempt to
split jobs into multiple smaller jobs and use the resulting freedom to
reschedule jobs in the queue.

For the $G/G/c$ queue we can use Sakasegawa's approximation, \cite{sakasegawa77:_l}, 
\begin{equation}\label{eq:7}
  \E{W_Q} = \frac{C_a^2+C_s^2}2 \frac{\rho^{\sqrt{2(c+1)}-1}}{c(1-\rho)} \E S
\end{equation}
to estimate the time in queue.  Here
\begin{equation*}
  \rho = \frac{\lambda \E S}{c}
\end{equation*}
is the load of the station, not of the individual machines. We refer to \cite{hopp08:_factor_physic} for a discussion of this formula and its many applications.


Even though the above results are only approximate, they prove to be
exceedingly useful when designing queueing systems and analyzing the
effect of certain changes, in particular  changes in capacity,
variability and service times.

\begin{exercise}($G/G/1$)
  Show that the approximation~\eqref{eq:7} reduces to the result known for the $M/M/1$ and $M/G/1$ queues.
  \begin{hint}
 Take $c=1$.
  \end{hint}
  \begin{solution}
    If $c=1$, as is the case for the $M/M/1$ queue, $\sqrt{2(c+1)} - 1=2-1=1$, so that~\eqref{eq:7} reduces to $\E{W_Q} = \rho/(1-\rho) \E S$. Recall that $C_a^2=C_s^2=1$ for the $M/M/1$. 
  \end{solution}
\end{exercise}





\begin{exercise}
  Is Eq.~\eqref{eq:24} also valid for the $G/G/1$ queue? Why (not)?
  \begin{solution}
    Not necessarily. Since jobs do not arrive in general as a Poisson
    process, we cannot use the PASTA property to conclude that the
    time average queue length $\E{L_Q}$ is the same as the average
    queue length as observed by customers.

(Can you provide an example that shows this difference?
    Hint, we did this earlier.)
  \end{solution}
\end{exercise}



\begin{exercise}
  Consider a queue $n$ servers, with generally distributed
  inter-arrival times, generally distributed service times, and the
  system can contain at most $K$ customers, i.e., the $G/G/n/K$ queue.
  Let $\lambda$ be the arrival rate, $\mu$ the service rate, $\beta$
  the long-run fraction of customers lost, and $\rho$  the average
  number of busy/occupied servers.
  Show that 
  \begin{equation*}
    \beta = 1 - \rho\frac{\mu}{\lambda}.
  \end{equation*}
\begin{solution}
  This follows from the observation that $\lambda(1-\beta)$ is the net
  arrival rate, as jobs are lost at a rate $\lambda\beta$ . Hence, the
  load must be $\lambda(1-\beta)/\mu$. As the load must be equal to
  $\rho$, it follows that $\rho = \lambda(1-\beta)/\mu$, from which the
  other result immediately follows.
\end{solution}
\end{exercise}

\begin{exercise}
 Consider a single-server queue at which every minute a
    customer arrives, precisely at the first second. Each customer
    requires precisely $50$ seconds of service. 
What are $\rho$,
    $\E L$, $C_a^2$, and $C_S^2$?
  \begin{solution}
 $\rho = \lambda \E S = 1/60 \cdot 50 = 5/6$. Since job
      arrivals do not overlap any job service, the number of jobs in
      the system is 1 for $50$ seconds, then the server is idle for 10
      seconds, and so on. Thus $\E L = 1\cdot5/6 = 5/6$. There is no
      variance in the inter-arrival times, and also not in the service
      times, thus $C_a^2 = C_s^2 = 0$. Also $\E{W_Q}=0$ since
      $\E{L_Q}=0$. Interestingly, we get the same from Kingman's formula.
  \end{solution}
\end{exercise}

\begin{exercise}
 Consider the same single-server system as in the previous exercise, but now the customer
    service time is stochastic: with probability $1/2$ a customer
    requires $1$ minute and $20$ seconds of service, and with
    probability $1/2$ the customer requires only $20$ seconds of
    service.  What are $\rho$, $C_a^2$, and $C_S^2$?
  \begin{solution}
 Again $\E S$ is 50 seconds, so that $\rho = 5/6$. Also
      $C_a^2=0$. For the $C_S^2$ we have to do some work. 
      \begin{equation*}
        \begin{split}
          \E S &=  \frac{20}2 + \frac{80}2 = 50 \\
          \E{S^2} &=  \frac{400}2 + \frac{6400} 2 = 3400 \\
          \V S &=  \E S^2 - (\E S)^2 = 3400 - 2500 = 900 \\
          C_S^2 &=  \frac{\V S}{(\E S)^2} = \frac{900}{2500}=\frac{9}{25}.
        \end{split}
      \end{equation*}
  \end{solution}
\end{exercise}

It is crucial to remember from the above exercises that knowledge of the   utilization is not sufficient to characterize the average queue   length.

\begin{exercise}
  For the $G/G/1$ queue, prove that the fraction of jobs that see $n$
  jobs in the system is the same as the fraction of departures that
  leave $n$ jobs behind. What condition have you used to prove this?
%\item Motivate that for  the $G/M/1$, $\delta(n) = p(n)$, i.e.,  departures see time averages. 
  \begin{solution}
    All follows straightaway from the definitions in the main text. In
    the $G/G/1$ queue jobs arrive and depart in single units. Hence,
    $|A(n,t)-D(n,t)|\leq 1$, c.f., Eq.~(\ref{eq:19}). Then, 
    \begin{equation*}
      \frac{A(t)}{t}\frac{A(n,t)}{A(t)} \approx 
      \frac{D(t)}{t}\frac{D(n,t)}{D(t)}. 
    \end{equation*}
    The left hand side goes to $\lambda \pi(n)$ as $t\to\infty$, and
    the right hand side to $\delta \delta(n)$. Use the fact that we
    always assume, implicitly, that the system is stable, so that
    $\lambda = \delta$. As a consequence $\delta(n) = \pi(n)$.
  \end{solution}
\end{exercise}

\begin{exercise}
  Suppose for the $G/G/1$ that a job sees $n$ jobs in the system upon
  arrival. Can you use the central limit law to estimate the
  distribution of waiting time in queue for this job?  
  \begin{hint}
 Let $S_n = \sum_{k=1}^n X_k$ and $\sigma_n^2 = n\V X$. Then,
    under conditions you can find on the internet,
    \begin{equation*}
    \frac{S_n - n \E X}{\sigma_n} \to \mathcal{N}(0,1), \quad\text{as } n\to \infty,
    \end{equation*}
    where $\mathcal{N}(0,1)$ is a normally distributed random variable
    with $\mu=0$ and $\sigma^2=1$. But then 
    \begin{align*}
    \frac{S_n - n \E X}{\sigma_n} &\approx  \mathcal{N}(0,1)  \iff\\
    S_n - n \E X &\approx  \sigma_n \mathcal{N}(0,1)  \iff\\
    S_n - n \E X &\approx  \mathcal{N}(0,\sigma_n^2)  \iff\\
    S_n  &\approx   n \E X + \mathcal{N}(0,\sigma_n^2)  \iff\\
    S_n  &\approx    \mathcal{N}(n \E X,\sigma_n^2),
    \end{align*}
    hence, $S_n$ is approximately distributed as
    $\mathcal{N}(n\E X, \sigma_n^2)$.
  \end{hint}
\begin{solution} If the number in the system is $n$, then the total
  service time required to process these $n$ jobs is the sum of the
  service times, i.e.,$W_{Q,n} = \sum_{k=1}^n S_k$ where $k$ counts over the
  $n$ jobs in the system. Then, with the hint,
  \begin{equation*}
    W_{Q, n} \sim  \mathcal{N}(n\E S, \sigma_n^2),
  \end{equation*}
where $\sigma_n^2 = n \V S$. 
Thus, the waiting time in queue is approximately normally distributed with mean $n \E S$ and variance $n \V S$. 
\end{solution}
\end{exercise}

\begin{exercise}
  (Hall 5.19) When a bus reaches the end of its line, it undergoes a
  series of inspections. The entire inspection takes 5 minutes on
  average, with a standard deviation of 2 minutes. Buses arrive with
  inter-arrival times uniformly distributed on $[3,9]$ minutes.

As a first case,  assuming a single server, estimate $\E{W_Q}$ with the $G/G/1$ waiting time formula. As a second case, compare this result to an $M/G/1$ system with arrival rate 10 per hour and the same service time distribution. Explain why your previous answer is smaller. 
  \begin{solution}
First the $G/G/1$ case. Observe that in this case, the inter-arrival time $X\sim U[3,9]$, that is, never smaller than 3 minutes, and never longer than 9 minutes. 

\begin{pyconsole}
  
a = 3.
b = 9. 
EX = (b+a)/2. # expected inter-arrival time
EX
labda = 1./EX # per minute
labda
VA = (b-a)*(b-a)/12.
CA2 = VA/(EX*EX)
CA2

ES = 5.
sigma = 2
VS = sigma*sigma
CS2 = VS/(ES*ES)
CS2

rho = labda*ES
rho

Wq = (CA2+CS2)/2. * rho/(1.-rho) * ES
Wq
\end{pyconsole}

Now  the $M/G/1$ case.

\begin{pyconsole}
Wq = (1.+CS2)/2. * rho/(1.-rho) * ES
Wq
\end{pyconsole}

The arrival process with uniform inter-arrival times is much more
regular than a Poisson process. In the first case, bus arrivals are
spaced in time at least with 3 minutes.
    \end{solution}
\end{exercise}



Clearly, Kingman's equation requires an estimate of the SCV $C_a^2$ of
the inter-arrival times and the SCV $C_s^2$ of the service times. Now
it is not always easy in practice to determine the actual service time
distribution, one reason being that service times are often only
estimated by a planner, but not actually measured. Similarly, the
actual arrival moments of jobs are often not registered, mostly just
the date or the hour, perhaps, that a customer arrived.  Hence, it is
often not possible to estimate $C_a^2$ and $C_s^2$ from information
that is available.  However, when for instance the number of arrivals
per day have been logged for some time so that we know
$\{a_n, n=1,\ldots, N\}$ for some $N$, we can use this information
instead of the inter-arrival times $\{X_k\}$ to obtain insight into
$C_a^2$.  The relation we present here to compute $C_a^2$ from
$\{a_n\}$ can of course also be applied to estimate $C_s^2$.

\begin{theorem} The SCV of the inter-arrival times can be estimated
  with the following formula
\begin{equation*}
C_a^2 \approx \frac{\tilde \sigma^2}{\tilde \lambda},
\end{equation*}
where 
\begin{equation*}
\tilde  \lambda = \lim_{n\to\infty} \frac 1n  \sum_{i=1}^n a_i,\quad  
\tilde  \sigma^2 = \lim_{n\to\infty} \frac 1 n \sum_{i=1}^n a_i^2 - \tilde \lambda^2,
\end{equation*}
in words, $\tilde \lambda$ is the average number of arrivals per
period, e.g., per day, and $\tilde \sigma^2 $ is the variance of the
number of arrivals per period.
\end{theorem}

\begin{proof}
  The proof is based on an argument in \cite{cox62:_renew_theor}. We
  use quite a bit of the notation developed in
  Section~\ref{sec:rate-stability}. Let $\{A(t), t\geq 0\}$ be the
  number of arrivals that occur up to (and including) time $t$. We
  assume that $\{A(t)\}$ is a renewal process such that the
  inter-arrival times $\{X_k, k=1, 2, \ldots\}$ with
  $X_k = A_{k}-A_{k-1}$, are i.i.d. with mean $1/\lambda$ and standard
  deviation~$\sigma$. (Observe that $\sigma$ is not the same as
  $\tilde \sigma$ above.) Note that $C_a^2$ is defined in terms of
  $\lambda$ and $\sigma$ as:
\begin{equation*}
C_a^2 = \frac{\V{X_i}}{(\E{X_i})^2} = \frac{\sigma^2}{1/\lambda^2} = \lambda^2 \sigma^2.
\end{equation*}

Next, let $A_k$ be the arrival time of the $k$th arrival. The
following useful relation between $A(t)$ and $A_k$ enables us to prove
our result (recall that we uses a similar relation in the derivation
of the Poisson process):
\begin{equation*}
\P{A(t) < k} = \P{A_k > t}.
\end{equation*}

Since the inter-arrival times have finite mean and second moment by
assumption, we can apply the central limit law to obtain that, as
$k\to\infty$,
\begin{equation*}
\frac{A_k -k/\lambda}{\sigma \sqrt k} \to N(0,1),
\end{equation*}
where $N(0,1)$ is a standard normal random variable with
distribution $\Phi(\cdot)$.  Similarly,
%
\begin{equation*}
\frac{A(t) -\lambda t}{\alpha \sqrt t} \to N(0,1)
\end{equation*}
for an $\alpha$ that is yet to be determined. Thus,
$\E{A(t)} = \lambda t$ and $\V{A(t)}=\alpha^2 t$.

Using that $\P{N(0,1) \leq y} =
\P{N(0,1) > -y}$ (and $\P{N(0,1)=y} = 0$) we have that
%
\begin{align*}
\Phi(y) &\approx \P{\frac{A_k - k/\lambda}{\sigma \sqrt k }\leq y} \\
        &= \P{\frac{A_k - k/\lambda}{\sigma \sqrt k} >  -y} \\
        &=  \P{A_k >  \frac k\lambda - y \sigma \sqrt k}.
\end{align*}
Define for ease
\begin{equation*}
t_k = \frac{k}\lambda - y \sigma \sqrt k.
\end{equation*}
We can use the above relation between the distributions of~$A(t)$
and~$A_k$ to see that~$\P{A_k >t_k } = \P{A(t_k) <k}$. With this we
get,
\begin{align*}
\Phi(y)
        &\approx  \P{A_k >  t_k } \\
        &=  \P{A(t_k) <  k } \\
        &=  \P{\frac{A(t_k) - \lambda t_k}{\alpha \sqrt{t_k}} < 
\frac{k-\lambda t_k}{\alpha \sqrt{t_k}}}.
\end{align*}
Since $(A(t_k) - \lambda t_k)/ \alpha \sqrt{t_k} \to N(0,1)$
as $t_k \to \infty$, the above implies that
\begin{equation*}
\frac{k-\lambda t_k}{\alpha \sqrt{t_k}} \to y,
\end{equation*}
as $t_k \to \infty$.  Using the above definition of $t_k$, the left
hand of this equation can be written as
\begin{equation*}
\frac{k-\lambda t_k}{\alpha \sqrt{t_k}} =
\frac{\lambda \sigma \sqrt k }{\alpha \sqrt{k/\lambda + \sigma\sqrt k}} y.
\end{equation*}
Since $t_k \to \infty$ is implied by (and implies)
$k\to\infty$, we therefore want that $\alpha$ is such that
\begin{equation*}
\frac{\lambda \sigma \sqrt k }{\alpha \sqrt{k/\lambda + \sigma\sqrt k}} y \to y,
\end{equation*}
as $k\to\infty$. This is precisely the case when
\begin{equation*}
\alpha = \lambda^{3/2}\sigma.
\end{equation*}
Finally, for $t$ large (or, by the same token $k$ large),
\begin{equation*}
\frac{\sigma_k^2}{\lambda_k} = \frac{\V{A(t)}}{\E{A(t)}} \approx \frac{\alpha^2 t}{\lambda t} 
= \frac{\alpha^2}{\lambda} = \frac{\lambda^3\sigma^2}{\lambda} = \lambda^2 \sigma^2 = C_a^2,
\end{equation*}
where the last equation follows from the above definition of $C_a^2$.  The proof is complete.
\end{proof}




\Closesolutionfile{hint}
\Closesolutionfile{ans}

\opt{solutionfiles}{
\subsection*{Hints}
\input{hint}
\subsection*{Solutions}
\input{ans}
}

%\clearpage


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../queueing_book"
%%% End:
